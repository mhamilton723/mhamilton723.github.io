<!DOCTYPE html><!--  This site was created in Webflow. https://webflow.com  --><!--  Last Published: Tue May 27 2025 22:12:30 GMT+0000 (Coordinated Universal Time)  -->
<html data-wf-page="681e655008b3856d0528a075" data-wf-site="5fd97fcae7aaf2c02444f619">
<head>
  <meta charset="utf-8">
  <title>Thesis</title>
  <meta content="Mark Hamilton&#x27;s PhD Thesis and Defense" name="description">
  <meta content="Thesis" property="og:title">
  <meta content="Mark Hamilton&#x27;s PhD Thesis and Defense" property="og:description">
  <meta content="https://mhamilton.net/images/thesis_thumb.png" property="og:image">
  <meta content="Thesis" property="twitter:title">
  <meta content="Mark Hamilton&#x27;s PhD Thesis and Defense" property="twitter:description">
  <meta content="https://mhamilton.net/images/thesis_thumb.png" property="twitter:image">
  <meta property="og:type" content="website">
  <meta content="summary_large_image" name="twitter:card">
  <meta content="width=device-width, initial-scale=1" name="viewport">
  <meta content="Webflow" name="generator">
  <link href="css/normalize.css" rel="stylesheet" type="text/css">
  <link href="css/webflow.css" rel="stylesheet" type="text/css">
  <link href="css/mhamilton723.webflow.css" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com" rel="preconnect">
  <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin="anonymous">
  <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
  <script type="text/javascript">WebFont.load({  google: {    families: ["Inconsolata:400,700","Roboto:100,300,regular,500,700"]  }});</script>
  <script type="text/javascript">!function(o,c){var n=c.documentElement,t=" w-mod-";n.className+=t+"js",("ontouchstart"in o||o.DocumentTouch&&c instanceof DocumentTouch)&&(n.className+=t+"touch")}(window,document);</script>
  <link href="images/favicon.ico" rel="shortcut icon" type="image/x-icon">
  <link href="images/webclip.png" rel="apple-touch-icon">
  <script async="" src="https://www.googletagmanager.com/gtag/js?id=G-V1K6GK8BBM"></script>
  <script type="text/javascript">window.dataLayer = window.dataLayer || [];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());gtag('set', 'developer_id.dZGVlNj', true);gtag('config', 'G-V1K6GK8BBM');</script>
</head>
<body class="body">
  <div data-collapse="small" data-animation="over-right" data-duration="400" data-easing="ease" data-easing2="ease" role="banner" class="nav w-nav">
    <div class="nav-container w-container">
      <nav role="navigation" class="nav-menu w-nav-menu">
        <div class="div-block">
          <a href="#Video" class="nav-link w-nav-link">Video</a>
          <a href="#Abstract" class="nav-link w-nav-link">Abstract</a>
          <a href="https://mhamilton.net/files/mark_hamilton_phd_thesis.pdf" target="_blank" class="nav-link w-nav-link">Thesis</a>
          <a href="#Related-Projects" class="nav-link w-nav-link">Related Projects</a>
          <a href="#Contact" class="nav-link w-nav-link">Contact</a>
        </div>
      </nav>
      <div class="menu-button w-nav-button">
        <div class="icon w-icon-nav-menu"></div>
      </div>
    </div>
  </div>
  <div id="Hero" class="paper-hero">
    <div class="hero-wrap"></div>
    <h1 class="paper-title">Unsupervised Discovery of Structure in Complex Systems</h1>
    <h1 class="h2">MIT PhD Thesis 2025</h1>
    <div class="paper-button-holder">
      <a target="_blank" href="https://mhamilton.net/files/mark_hamilton_phd_thesis.pdf" class="button w-button">Thesis PDF</a>
    </div>
    <div class="spacer"></div>
    <h1 class="paper-names">
      <a href="https://mhamilton.net" target="_blank" class="link">Mark Hamilton</a> <br>PhD Advisor: <a href="https://billf.mit.edu/" target="_blank" class="link">William T. Freeman</a>
    </h1>
    <div class="w-layout-grid affiliationholder"><img src="images/mit_logo_white.svg" loading="lazy" alt="" id="w-node-_185912c3-010d-fb94-8b11-ceb325f173f4-0528a075" class="affiliation-image"><img src="images/msft_logo_white.svg" loading="lazy" alt="" class="affiliation-image"></div>
    <div class="w-layout-blockcontainer section-width w-container">
      <div class="tldr-text"><strong>TL;DR</strong>: How can we build algorithms that learn without human labels, so that we can use AI to help solve scientific challenges humans dont yet know how to solve.</div>
    </div>
  </div>
  <div id="Video" class="section">
    <div class="section-margin">
      <div class="paper-page-section-width">
        <div style="padding-top:56.17021276595745%" class="w-embed-youtubevideo"><iframe src="https://www.youtube.com/embed/pieFUTCzKvA?rel=0&amp;controls=1&amp;autoplay=0&amp;mute=0&amp;start=0" frameborder="0" style="position:absolute;left:0;top:0;width:100%;height:100%;pointer-events:auto" allow="autoplay; encrypted-media" allowfullscreen="" title="Mark Hamilton PhD Defense"></iframe></div>
      </div>
    </div>
    <h1 class="paper-section-header">Abstract</h1>
  </div>
  <div id="Abstract" class="section">
    <div class="section-margin">
      <div class="section-width">
        <div class="small-spacer"></div>
        <h1 class="paper-page-text-block">How does the human mind make sense of raw information without being taught how to see or hear? This thesis presents a <strong>unifying theory</strong> that describes how algorithms can learn and discover structure in complex systems, like natural images, audio, language, and video - <strong>without human input</strong>. This class of algorithms has the possibility to extend our own understanding of the world by helping us to see previously unseen patterns in nature and science. At the core of this thesis&#x27; unified theory is the notion that <em>relationships</em> between deep network representations hold the key discover the structure of the world without human input. This work will begin with a few examples of this principle in action; discovering hidden connections that span cultures and millennia in the visual arts, discovering visual objects in large image corpora, classifying every pixel of our visual world, and rediscovering the meaning of words from raw audio, all without human labels. In the latter half of this thesis, we will present two unifying mathematical theories of unsupervised learning. The first will explain why relationships between deep features can rediscover the semantic structure of the natural world by connecting model explainability, cooperative game theory, and deep feature relationships. The second mathematical theory will show that relationships between representations can be used to unify over 20 common machine learning algorithms spanning 100 years of progress in the field of machine learning. In particular, we introduce a single equation that unifies classification, regression, large language modeling, dimensionality reduction, clustering, contrastive learning, and spectral methods. This thesis uses this unified equation as the basis for a &quot;periodic table of representation learning&quot; that predicts the existence of new types of algorithms. We show that one of these predicted algorithms is a state-of-the-art unsupervised image classification technique. Finally, this work will summarize the key findings and share ongoing and future directions.</h1>
      </div>
    </div>
  </div>
  <div id="Related-Projects" class="section">
    <div class="section-margin">
      <div class="section-width">
        <h1 class="paper-section-header">Papers in This Thesis</h1>
        <div class="small-spacer"></div>
        <div class="paper-entry">
          <div class="pub-image-div">
            <div class="pub-img w-embed">
              <style>
    @media (max-width: 480px) {
        .responsive-video {
            max-height: 200px;
        }
    }
</style>
              <video playsinline="" autoplay="" loop="" preload="" muted="" class="responsive-video" style="max-width: 100%; object-fit: contain;">
                <source src="https://mhamilton.net/videos/CIR.mp4" type="video/mp4">
              </video>
            </div>
          </div>
          <div class="pub-item">
            <h2 class="paper-titile">MosAIc: Finding Artistic Connections across Culture with Conditional Image Retrieval</h2>
            <div class="paper-buttons">
              <a target="_blank" href="https://arxiv.org/abs/2007.07177" class="button w-button">Paper</a>
              <a target="_blank" href="http://www.aka.ms/mosaic" class="button w-button">Website</a>
              <a target="_blank" href="https://note.microsoft.com/MSR-Webinar-Visual-Analogies-Registration-On-Demand.html" class="button w-button">Webinar</a>
              <a target="_blank" href="https://youtu.be/y0iYKr9ayfE" class="button w-button">Talk</a>
              <a target="_blank" href="https://github.com/microsoft/art" class="button w-button">Code</a>
              <a target="_blank" href="https://raw.githubusercontent.com/mhamilton723/mhamilton723.github.io/master/files/bib/hamilton2020conditional.bib" class="button w-button">BibTex</a>
            </div>
            <h1 class="author-list">Relationships between visual features can discover hissen connections in visual arts.</h1>
          </div>
        </div>
        <div class="paper-entry">
          <div class="pub-image-div"><img src="images/ezgif.com-gif-maker-3.gif" width="436" alt="" loading="lazy" class="pub-img"></div>
          <div class="pub-item">
            <h2 class="paper-titile">Unsupervised Semantic Segmentation by Distilling Feature Correspondences<br></h2>
            <div class="paper-buttons">
              <a target="_blank" href="stego.html" class="button w-button">Website</a>
              <a target="_blank" href="https://arxiv.org/abs/2203.08414" class="button w-button">Paper</a>
              <a target="_blank" href="https://iclr.cc/virtual/2022/poster/6068" class="button w-button">Talk</a>
              <a target="_blank" href="https://github.com/mhamilton723/STEGO" class="button w-button">Github</a>
              <a target="_blank" href="https://raw.githubusercontent.com/mhamilton723/mhamilton723.github.io/master/files/bib/hamilton2022unsupervised.bib" class="button w-button">BibTex</a>
            </div>
            <h1 class="author-list">We show that its possible to classify every pixel of the visual world without human labels.</h1>
          </div>
        </div>
        <div class="paper-entry">
          <div class="pub-image-div">
            <div class="pub-img w-embed">
              <style>
    @media (max-width: 480px) {
        .responsive-video {
            max-height: 200px;
        }
    }
</style>
              <video playsinline="" autoplay="" loop="" preload="" muted="" class="responsive-video" style="max-width: 100%; object-fit: contain;">
                <source src="https://mhamilton.net/videos/featup_teaser.mp4" type="video/mp4">
              </video>
            </div>
          </div>
          <div class="pub-item">
            <h2 class="paper-titile">FeatUp: A Model-Agnostic Framework for Features at Any Resolution<br></h2>
            <div class="paper-buttons">
              <a target="_blank" href="featup.html" class="button w-button">Website</a>
              <a target="_blank" href="https://aka.ms/featup-paper" class="button w-button">Paper</a>
              <a target="_blank" href="https://github.com/mhamilton723/FeatUp" class="button w-button">Github</a>
              <a target="_blank" href="https://raw.githubusercontent.com/mhamilton723/mhamilton723.github.io/master/files/bib/fu2024featup.bib" class="button w-button">BibTex</a>
            </div>
            <h1 class="author-list">By looking at how deep features change we can improve the resoltion of depe visual features by up to 64x without changing their semantics.</h1>
          </div>
        </div>
        <div class="paper-entry">
          <div class="pub-image-div">
            <div class="pub-img w-embed">
              <style>
    @media (max-width: 480px) {
        .responsive-video {
            max-height: 200px;
        }
    }
</style>
              <video playsinline="" autoplay="" loop="" preload="" muted="" class="responsive-video" style="max-width: 100%; object-fit: contain;">
                <source src="https://mhamilton.net/videos/denseav_teaser_trimmed_silent.mp4" type="video/mp4">
              </video>
            </div>
          </div>
          <div class="pub-item">
            <h2 class="paper-titile">Separating the &quot;Chirp&quot; from the &quot;Chat&quot;: Self-supervised Visual Grounding of Sound and Language<br></h2>
            <div class="paper-buttons">
              <a target="_blank" href="denseav.html" class="button w-button">Website</a>
              <a target="_blank" href="https://aka.ms/denseav-paper" class="button w-button">Paper</a>
              <a target="_blank" href="https://www.youtube.com/watch?v=rD2kfwu1fYE&amp;list=PLBJWRPcgwk7vVzKLPnTrqm831VohoLMmy&amp;index=4" class="button w-button">Talk</a>
              <a target="_blank" href="https://github.com/mhamilton723/DenseAV" class="button w-button">Github</a>
              <a target="_blank" href="https://raw.githubusercontent.com/mhamilton723/mhamilton723.github.io/master/files/bib/hamilton2024separating.bib" class="button w-button">BibTex</a>
            </div>
            <h1 class="author-list">We show that its possible to rediscover language without human labels or text - just by watching unlabelled videos.</h1>
          </div>
        </div>
        <div class="paper-entry">
          <div class="pub-image-div">
            <div class="pub-img w-embed">
              <style>
    @media (max-width: 480px) {
        .responsive-video {
            max-height: 200px;
        }
    }
</style>
              <video playsinline="" autoplay="" loop="" preload="" muted="" class="responsive-video" style="max-width: 100%; object-fit: contain;">
                <source src="https://mhamilton.net/videos/projection.mp4" type="video/mp4">
              </video>
            </div>
          </div>
          <div class="pub-item">
            <h2 class="paper-titile">Axiomatic Explanations for Visual Search, Retrieval, and Similarity Learning<br></h2>
            <div class="paper-buttons">
              <a target="_blank" href="axiomatic.html" class="button w-button">Website</a>
              <a target="_blank" href="https://arxiv.org/abs/2103.00370" class="button w-button">Paper</a>
              <a target="_blank" href="https://iclr.cc/virtual/2022/poster/6983" class="button w-button">Talk</a>
              <a target="_blank" href="https://raw.githubusercontent.com/mhamilton723/mhamilton723.github.io/master/files/bib/hamilton2021model.bib" class="button w-button">BibTex</a>
            </div>
            <h1 class="author-list">We introduce a unifying framework for understanding search engines and other unsupervised algorithms. This connects game theory, model explainability, and feature relationships formally. Explaining why these relationships used in the thesis work so well.</h1>
          </div>
        </div>
        <div class="paper-entry">
          <div class="pub-image-div">
            <div class="pub-img w-embed">
              <style>
    @media (max-width: 480px) {
        .responsive-video {
            max-height: 200px;
        }
    }
</style>
              <video playsinline="" autoplay="" loop="" preload="" muted="" class="responsive-video" style="max-width: 100%; object-fit: contain;">
                <source src="https://mhamilton.net/videos/denseav_teaser_trimmed_silent.mp4" type="video/mp4">
              </video>
            </div><img src="images/icon_og.svg" width="436" alt="" loading="lazy" class="pub-img">
          </div>
          <div class="pub-item">
            <h2 class="paper-titile">I-Con: A Unifying Framework for Representation Learning<br></h2>
            <div class="paper-buttons">
              <a target="_blank" href="icon.html" class="button w-button">Website</a>
              <a target="_blank" href="https://aka.ms/icon-paper" class="button w-button">Paper</a>
              <a target="_blank" href="https://aka.ms/icon-code" class="button w-button">Github</a>
              <a target="_blank" href="https://raw.githubusercontent.com/mhamilton723/mhamilton723.github.io/master/files/bib/alshammari2025a.bib" class="button w-button">BibTex</a>
            </div>
            <h1 class="author-list">We introduce a single equation that unifies 23+ machine learning algorithms. We use this equation to introduce a periodic table of machine learning. Several of the works of this thesis appear in the table. </h1>
          </div>
        </div>
      </div>
    </div>
  </div>
  <div id="Contact" class="section">
    <div class="section-margin">
      <div class="section-width">
        <h1 class="paper-section-header">Contact</h1>
        <div class="small-spacer"></div>
        <h1 class="paper-page-text-block">For feedback, questions, or press inquiries please contact <a href="mailto:markth@mit.edu" class="link">Mark Hamilton</a>
        </h1>
      </div>
      <div class="footer"></div>
    </div>
  </div>
  <script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=5fd97fcae7aaf2c02444f619" type="text/javascript" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
  <script src="js/webflow.js" type="text/javascript"></script><!-- <script async src="lib/particles.min.js"></script>  -->
</body>
</html>