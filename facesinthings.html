<!DOCTYPE html><!--  This site was created in Webflow. https://webflow.com  --><!--  Last Published: Mon Nov 18 2024 04:57:10 GMT+0000 (Coordinated Universal Time)  -->
<html data-wf-page="668edb0106802ddd9a32d5bc" data-wf-site="5fd97fcae7aaf2c02444f619">
<head>
  <meta charset="utf-8">
  <title>FacesInThings</title>
  <meta content="Seeing Faces in Things: A Model and Dataset for Pareidolia - ECCV 2024" name="description">
  <meta content="FacesInThings" property="og:title">
  <meta content="Seeing Faces in Things: A Model and Dataset for Pareidolia - ECCV 2024" property="og:description">
  <meta content="https://marhamilresearch4.blob.core.windows.net/pareidolia-public/dataset_summary%20(1).jpg" property="og:image">
  <meta content="FacesInThings" property="twitter:title">
  <meta content="Seeing Faces in Things: A Model and Dataset for Pareidolia - ECCV 2024" property="twitter:description">
  <meta content="https://marhamilresearch4.blob.core.windows.net/pareidolia-public/dataset_summary%20(1).jpg" property="twitter:image">
  <meta property="og:type" content="website">
  <meta content="summary_large_image" name="twitter:card">
  <meta content="width=device-width, initial-scale=1" name="viewport">
  <meta content="Webflow" name="generator">
  <link href="css/normalize.css" rel="stylesheet" type="text/css">
  <link href="css/webflow.css" rel="stylesheet" type="text/css">
  <link href="css/mhamilton723.webflow.css" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com" rel="preconnect">
  <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin="anonymous">
  <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
  <script type="text/javascript">WebFont.load({  google: {    families: ["Inconsolata:400,700","Roboto:100,300,regular,500,700"]  }});</script>
  <script type="text/javascript">!function(o,c){var n=c.documentElement,t=" w-mod-";n.className+=t+"js",("ontouchstart"in o||o.DocumentTouch&&c instanceof DocumentTouch)&&(n.className+=t+"touch")}(window,document);</script>
  <link href="images/favicon.ico" rel="shortcut icon" type="image/x-icon">
  <link href="images/webclip.png" rel="apple-touch-icon">
  <script async="" src="https://www.googletagmanager.com/gtag/js?id=G-V1K6GK8BBM"></script>
  <script type="text/javascript">window.dataLayer = window.dataLayer || [];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());gtag('set', 'developer_id.dZGVlNj', true);gtag('config', 'G-V1K6GK8BBM');</script>
</head>
<body class="body">
  <div data-collapse="small" data-animation="over-right" data-duration="400" data-easing="ease" data-easing2="ease" role="banner" class="nav w-nav">
    <div class="nav-container w-container">
      <nav role="navigation" class="nav-menu w-nav-menu">
        <div class="div-block">
          <a href="#Video" class="nav-link w-nav-link">Video</a>
          <a href="#Abstract" class="nav-link w-nav-link">Abstract</a>
          <a href="#About" class="nav-link w-nav-link">About</a>
          <a href="https://aka.ms/denseav-paper" target="_blank" class="nav-link w-nav-link">Paper</a>
          <a href="#Contact" class="nav-link w-nav-link">Contact</a>
        </div>
      </nav>
      <div class="menu-button w-nav-button">
        <div class="icon w-icon-nav-menu"></div>
      </div>
    </div>
  </div>
  <div id="Hero" class="paper-hero">
    <div class="hero-wrap"></div>
    <h1 class="paper-title">Seeing Faces in Things:<br>A Model and Dataset for Pareidolia</h1>
    <h1 class="h2">ECCVÂ 2024</h1>
    <div class="paper-button-holder">
      <a target="_blank" href="https://aka.ms/faces-paper" class="button w-button">Paper</a>
      <a target="_blank" href="https://aka.ms/faces-code" class="button w-button">Code</a>
      <a target="_blank" href="https://aka.ms/faces-dataset" class="button w-button">Dataset</a>
      <a target="_blank" href="https://www.youtube.com/watch?v=ZfQivjm8OaI" class="button w-button">Talk</a>
    </div>
    <div class="spacer"></div>
    <h1 class="paper-names">
      <a href="https://mhamilton.net" target="_blank" class="link">Mark Hamilton</a>, <a href="https://scholar.google.com/citations?user=f3aij5UAAAAJ&amp;hl=en" target="_blank" class="link">Simon Stent</a>, <a href="https://vashadutell.com/" target="_blank" class="link">Vasha DuTell</a>, <a href="https://persci.mit.edu/people/anne" target="_blank" class="link">Anne Harrington</a>, <a href="https://persci.mit.edu/people/jennifercorbett/" target="_blank" class="link">Jennifer Corbett</a>, <a href="https://persci.mit.edu/people/rosenholtz" target="_blank" class="link">Ruth Rosenholtz</a>, <a href="https://billf.mit.edu/about/bio" target="_blank" class="link">William T. Freeman</a>
    </h1>
    <div class="w-layout-grid affiliationholder"><img src="images/mit_logo_white.svg" loading="lazy" alt="" id="w-node-_43a3413d-4adf-1800-f7a1-439b5010f325-9a32d5bc" class="affiliation-image"><img src="images/msft_logo_white.svg" loading="lazy" alt="" class="affiliation-image"><img src="images/Toyota_Research_Institute_Logo.svg" loading="lazy" alt="" class="affiliation-image"><img src="images/Nvidia-White-Horizontal-Logo.wine.svg" loading="lazy" alt="" class="affiliation-image"></div>
    <div class="paper-page-section-width"><img src="images/6408d4de732708fb1275cd71_black_bg_dataset.jpg" loading="lazy" width="559" sizes="(max-width: 479px) 89vw, (max-width: 767px) 93vw, (max-width: 991px) 88vw, 749.9999389648438px" alt="" srcset="images/6408d4de732708fb1275cd71_black_bg_dataset-p-500.jpg 500w, images/6408d4de732708fb1275cd71_black_bg_dataset-p-800.jpg 800w, images/6408d4de732708fb1275cd71_black_bg_dataset-p-1080.jpg 1080w, images/6408d4de732708fb1275cd71_black_bg_dataset-p-1600.jpg 1600w, images/6408d4de732708fb1275cd71_black_bg_dataset-p-2000.jpg 2000w, images/6408d4de732708fb1275cd71_black_bg_dataset.jpg 2400w" class="paper-image">
      <div class="tldr-text"><strong>TL;DR</strong>: We introduce a dataset of over 5000 human annotated pareidolic images. We also link pareidolia in algorithms to the process of learning to detect animal faces.</div>
    </div>
  </div>
  <div id="Video" class="section">
    <div class="section-margin">
      <div class="paper-page-section-width">
        <div style="padding-top:56.17021276595745%" class="w-embed-youtubevideo youtube"><iframe src="https://www.youtube.com/embed/kBy0Mae0zR8?rel=0&amp;controls=1&amp;autoplay=0&amp;mute=0&amp;start=0" frameborder="0" style="position:absolute;left:0;top:0;width:100%;height:100%;pointer-events:auto" allow="autoplay; encrypted-media" allowfullscreen="" title="Seeing Faces in Things: A Model and Dataset for Pareidolia - ECCV 2024"></iframe></div>
      </div>
    </div>
  </div>
  <div id="Abstract" class="section">
    <div class="section-margin">
      <div class="paper-page-section-width">
        <h1 class="paper-section-header">Abstract</h1>
        <div class="small-spacer"></div>
        <h1 class="paper-page-text-block">The human visual system is well-tuned to detect faces of all shapes and sizes. While this brings obvious survival advantages, such as a better chance of spotting unknown predators in the bush, it also leads to spurious face detections. &quot;Face pareidolia&quot; describes the perception of face-like structure among otherwise random stimuli: seeing faces in coffee stains or clouds in the sky. In this paper, we study face pareidolia from a computer vision perspective. We present an image dataset of &quot;Faces in Things&quot;, consisting of five thousand web images with human-annotated pareidolic faces. Using this dataset, we examine the extent to which a state-of-the-art human face detector exhibits pareidolia, and find a significant behavioral gap between humans and machines. We explore a variety of different strategies to close this gap and discover that the evolutionary need for humans to detect animal faces, as well as human faces, explains some of this gap. Finally, we propose a simple statistical model of pareidolia in images. Through studies on human subjects and our pareidolic face detectors we confirm a key prediction of our model regarding what image conditions are most likely to induce pareidolia.</h1>
      </div>
    </div>
  </div>
  <div id="About" class="section">
    <div class="section-margin">
      <article class="paper-page-section-width">
        <h1 class="paper-section-header">The Faces in Things Dataset</h1>
        <div class="small-spacer"></div>
        <h1 class="paper-page-text-block">We introduce an annotated dataset of five thousand human labeled pareidolic face images, called ``Faces in Things&#x27;&#x27;. Faces in Things is derived from the LAION-5B dataset and annotated for key face attributes and bounding boxes</h1><img sizes="(max-width: 479px) 93vw, (max-width: 767px) 95vw, (max-width: 991px) 90vw, 749.9999389648438px" srcset="images/6408d4de732708fb1275cd71_black_bg_dataset-p-500.jpg 500w, images/6408d4de732708fb1275cd71_black_bg_dataset-p-800.jpg 800w, images/6408d4de732708fb1275cd71_black_bg_dataset-p-1080.jpg 1080w, images/6408d4de732708fb1275cd71_black_bg_dataset-p-1600.jpg 1600w, images/6408d4de732708fb1275cd71_black_bg_dataset-p-2000.jpg 2000w, images/6408d4de732708fb1275cd71_black_bg_dataset.jpg 2400w" alt="" src="images/6408d4de732708fb1275cd71_black_bg_dataset.jpg" loading="lazy" class="image-3">
      </article>
      <div class="paper-page-section-width">
        <h1 class="paper-section-header">Linking Face Pareidolia to Animal Face Detection</h1>
        <div class="small-spacer"></div><img sizes="(max-width: 479px) 93vw, (max-width: 767px) 95vw, (max-width: 991px) 90vw, 749.9999389648438px" srcset="images/animal-face-connections-p-500.jpg 500w, images/animal-face-connections-p-800.jpg 800w, images/animal-face-connections-p-1080.jpg 1080w, images/animal-face-connections-p-1600.jpg 1600w, images/animal-face-connections.jpg 1729w" alt="" src="images/animal-face-connections.jpg" loading="lazy" class="pareidolia-dog-image">
        <h1 class="paper-page-text-block">Using our dataset, we find that several modern face detectors do not experience pareidolia to the same extent humans do. Interestingly, we show that pareidolic face detection can be significantly improved by <strong>fine-tuning a face detector on animal faces</strong>. This effect accounts for roughly <strong>half of the gap</strong> between a pareidolia fine-tuned algorithm, and a human face fine-tuned algorithm. This sheds new light on why humans might experience pareidolia. Â </h1><img sizes="(max-width: 479px) 93vw, (max-width: 767px) 95vw, (max-width: 991px) 90vw, 749.9999389648438px" srcset="images/improvement_vs_dataset_black-p-500.png 500w, images/improvement_vs_dataset_black.png 640w" alt="" src="images/improvement_vs_dataset_black.png" loading="lazy" class="pareidolia-graph-image">
        <h1 class="paper-page-text-block">We can even use the deep feature representation of our trained animal and pareidolia detector to compute animal-pareidolia doppelgangers:</h1><img sizes="(max-width: 479px) 93vw, (max-width: 767px) 95vw, (max-width: 991px) 90vw, 749.9999389648438px" srcset="images/animal_pareidolia_black_opt-p-500.jpg 500w, images/animal_pareidolia_black_opt-p-800.jpg 800w, images/animal_pareidolia_black_opt-p-1080.jpg 1080w, images/animal_pareidolia_black_opt-p-1600.jpg 1600w, images/animal_pareidolia_black_opt-p-2000.jpg 2000w, images/animal_pareidolia_black_opt.jpg 2500w" alt="" src="images/animal_pareidolia_black_opt.jpg" loading="lazy" class="image-3">
      </div>
      <div class="paper-page-section-width">
        <h1 class="paper-section-header">Predicting Pareidolia in Humans and Machines</h1>
        <div class="small-spacer"></div>
        <h1 class="paper-page-text-block">Why do some patterns and textures, like the surface of themoon, always seem to provoke pareidolia while others do not? To answer this question,we introduce a simple closed-form model of pareidolic face detection andanalyze its behavior. We find evidence of a &quot;goldilocks&quot; zone wherethe probability of pareidolia is maximized. Intuitively, this occurs when animage generation process is rich enough to match the main spatial modes of a facebut isnât too rich to make it difficult to match these modes. We measure theexistence of this zone in both humans and machines.</h1><img sizes="(max-width: 479px) 93vw, (max-width: 767px) 95vw, (max-width: 991px) 90vw, 749.9999389648438px" srcset="images/GaussianModelPanel2_black_opt-p-500.jpg 500w, images/GaussianModelPanel2_black_opt-p-800.jpg 800w, images/GaussianModelPanel2_black_opt-p-1080.jpg 1080w, images/GaussianModelPanel2_black_opt-p-1600.jpg 1600w, images/GaussianModelPanel2_black_opt-p-2000.jpg 2000w, images/GaussianModelPanel2_black_opt-p-2600.jpg 2600w, images/GaussianModelPanel2_black_opt-p-3200.jpg 3200w, images/GaussianModelPanel2_black_opt.jpg 3814w" alt="" src="images/GaussianModelPanel2_black_opt.jpg" loading="lazy" class="image-3">
      </div>
    </div>
  </div>
  <div id="Paper" class="section">
    <div class="section-margin">
      <div class="paper-page-section-width">
        <h1 class="paper-section-header">Paper</h1>
        <div class="small-spacer"></div>
        <a href="https://aka.ms/faces-paper" target="_blank" class="w-inline-block"><img src="images/paper_viz.jpg" loading="lazy" sizes="(max-width: 479px) 93vw, (max-width: 767px) 95vw, (max-width: 991px) 90vw, 749.9999389648438px" srcset="images/paper_viz-p-500.jpg 500w, images/paper_viz-p-800.jpg 800w, images/paper_viz-p-1080.jpg 1080w, images/paper_viz.jpg 1320w" alt="" class="paper-thumbnail"></a>
      </div>
      <div class="paper-page-section-width">
        <h1 class="paper-section-header">Bibtex</h1>
        <div class="small-spacer"></div>
        <div class="code-block"><code class="code">@misc{<br>Â Â Â Â hamilton2024seeingfacesthingsmodel,<br>Â Â Â Â title={Seeing Faces in Things: A Model and Dataset for Pareidolia}, <br>Â Â Â Â author={Mark Hamilton and<br>Â Â Â Â Â Â Â Â Â Â Â  Simon Stent and <br>Â Â Â Â Â Â Â Â Â Â Â Â Vasha DuTell and<br>Â Â Â Â Â Â Â Â Â Â Â Â Anne Harrington and<br>Â Â Â Â Â Â Â Â Â Â Â  Jennifer Corbett and<br>Â Â Â Â Â Â Â Â Â Â Â  Ruth Rosenholtz and<br>Â Â Â Â Â Â Â Â Â Â Â  William T. Freeman},<br>Â Â Â Â year={2024},<br>Â Â Â Â eprint={2409.16143},<br>Â Â Â Â archivePrefix={arXiv},<br>Â Â Â Â primaryClass={cs.CV},<br>Â Â Â Â url={https://arxiv.org/abs/2409.16143},<br>}</code></div>
      </div>
    </div>
  </div>
  <div id="Contact" class="section">
    <div class="section-margin">
      <div class="paper-page-section-width">
        <h1 class="paper-section-header">Contact</h1>
        <div class="small-spacer"></div>
        <h1 class="paper-page-text-block">For feedback, questions, or press inquiries please contact <a href="mailto:markth@mit.edu?subject=FeatUp" class="link">Mark Hamilton</a>
        </h1>
      </div>
      <div class="footer"></div>
    </div>
  </div>
  <script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=5fd97fcae7aaf2c02444f619" type="text/javascript" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
  <script src="js/webflow.js" type="text/javascript"></script><!-- <script async src="lib/particles.min.js"></script>  -->
</body>
</html>